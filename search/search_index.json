{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ramprasad Guduru","text":""},{"location":"#devops-engineer","title":"DevOps Engineer","text":""},{"location":"#summary","title":"Summary","text":"<p>I'm Ramaprasad Guduru working as a DevOps Engineer. I have Experience in Provisioning and Managing Cloud Infrastructure. Automating maintenance and regular jobs on Cloud Infrastructure. Experience handling the Entire Project Lifecycle.</p>"},{"location":"#customization","title":"Customization","text":"<p>social media:       - LinkedIn       - Instagram       - FaceBook       - Site       - medium</p>"},{"location":"#site-is-under-maintenance","title":"(SITE IS UNDER MAINTENANCE....................)","text":""},{"location":"Azure-DevOps-Introduction/","title":"Azure DevOps Introduction","text":"<p>Azure DevOps includes everything you need to plan, develop, test, and deploy your applications, all in one place. Here\u2019s a quick overview of the core components:</p> Component Description Boards Use Agile boards to track work items and assign tasks to team members. Repos Host your code in Git repositories and collaborate with others using pull requests and code reviews. Pipelines Automate your build, test, and deployment processes with continuous integration and continuous deployment (CI/CD) pipelines. Test Plans Plan, track, and execute manual and exploratory testing. Artifacts Host and manage packages, such as NuGet and npm, and share them across your organization. <p>With Azure DevOps, you can integrate with your favorite tools and frameworks, including Visual Studio, Eclipse, Jenkins, and many others. Plus, it supports a wide range of languages, platforms, and operating systems, so you can build and deploy applications regardless of your technology stack.</p>"},{"location":"Azure-DevOps-Introduction/#benefits-of-azure-devops","title":"Benefits of Azure DevOps","text":"Benefit Description Faster time-to-market By automating your delivery pipeline, you can reduce manual errors and speed up the time it takes to get your application into the hands of your customers. Improved collaboration With all your tools in one place, your team can collaborate more effectively and reduce communication barriers. Increased visibility With Agile boards, you can track progress and identify bottlenecks in your development process, allowing you to make data-driven decisions to improve your workflow. Greater quality By integrating testing and deployment into your pipeline, you can catch bugs and issues early, leading to higher-quality software. <p>Whether you\u2019re a small startup or a large enterprise, Azure DevOps can help you streamline your software delivery pipeline and improve the quality of your applications. Try it out for yourself and see how it can transform your development process.</p>"},{"location":"Important%20Basics%20of%20Azure%20DevOps/","title":"Important Basics of Azure DevOps \ud83e\udde9","text":"<p>Important Basics of Azure DevOps</p> <p>Azure DevOps is a cloud-based service provided by Microsoft that offers a set of tools for software development, testing, and deployment.</p> <p>It includes a range of services such as Azure Boards, Azure Repos, Azure Test Plans, and Azure Pipelines, among others.</p> <p>Azure Boards is a project management tool that helps teams plan, track, and manage their work.</p> <p>Azure Repos is a version control system that allows teams to manage their source code.</p> <p>Azure Test Plans is a testing tool that enables teams to create and run manual and automated tests.</p> <p>Azure Pipelines is a continuous integration and continuous delivery (CI/CD) service that enables teams to build, test, and deploy their applications.</p> <p>Azure DevOps supports various programming languages and platforms such as .NET, Java, Node.js, Python, and others.</p> <p>It offers integration with other Microsoft services such as Azure, Visual Studio, and Office 365, as well as with third-party tools and services.</p> <p>Azure DevOps provides a robust security and compliance framework that includes features such as role-based access control, auditing, and compliance reporting.</p> <p>Azure DevOps pricing is based on usage, and it offers a range of plans and options to suit different needs and budgets.</p>"},{"location":"Terraform-commands/","title":"Terraform-All-Commands \ud83d\udee0\ufe0f","text":"S.No Command Description 1 <code>Terraform init</code> To initialize, provide the plugins, and require the dependency lock files. 2 <code>Terraform init --upgrade</code> Upgrade the version of the provided plugins. 3 <code>terraform get</code> Download and update the dependencies. 4 <code>Terraform plan</code> Execution of the providers in the Terraform configuration. 5 <code>Terraform apply</code> Used to apply changes and create the infrastructure. 6 <code>Terraform apply -auto-approve</code> Used to apply changes and create the infrastructure without approval. 7 <code>Terraform apply -replace=&lt;resource_name&gt;</code> Used to replace a specific resource in your infrastructure. 8 <code>Terraform workspace new</code> To create a new workspace in your Terraform configuration. 9 <code>Terraform workspace list</code> To display the list of workspaces in your Terraform configuration. 10 <code>Terraform workspace select &lt;workspace_name&gt;</code> To switch to a different workspace in your Terraform configuration. 11 <code>Terraform workspace delete &lt;workspace_name&gt;</code> To delete a specific workspace. 12 <code>Terraform workspace show</code> To display the name of the current workspace. 13 <code>Terraform import resource_name.attribute</code> To import existing resources into a Terraform state file. 14 <code>Terraform show</code> To display the current state of your infrastructure as represented by the Terraform state file. 15 <code>Terraform destroy</code> To destroy the total infrastructure created by Terraform. 16 <code>Terraform apply destroy --auto-approve</code> To destroy resources without approval. 17 <code>Terraform providers</code> To list currently installed providers on your system. 18 <code>Terraform version</code> To display the current version of Terraform. 19 <code>Terraform output</code> To display the values of the output variables defined in your Terraform configuration. 20 <code>Terraform state pull</code> To download the current state data. 21 <code>Terraform state list</code> To list all resources managed by Terraform. 22 <code>Terraform validate</code> To validate the syntax and configuration of Terraform files. 23 <code>Terraform fmt</code> To format Terraform configuration files in canonical and aligned format. 24 <code>Terraform refresh</code> To update only modified files in your Terraform configuration. 25 <code>Terraform mv</code> To move or rename files or directories in a Terraform configuration. 26 <code>Terraform state push</code> To upload the local state file to a remote state. 27 <code>Terraform providers lock</code> To lock provider dependencies for a Terraform configuration."},{"location":"Versioncontrolwithgit/","title":"Version control with Git \ud83d\udd04","text":"<p>Git is a distributed version control system, which means that each person who works on a project has their own copy of the entire project, including its history. When someone makes a change and pushes it to the central repository, everyone else can pull the changes down and merge them into their own copy of the project.</p> <p>Git is a great tool for collaboration, as it allows people to work independently on their own copies of the project and then easily merge their changes together. It also makes it easy to roll back changes if something goes wrong.</p>"},{"location":"about/","title":"Ramaparasad Guduru","text":""},{"location":"about/#devops-engineer","title":"DevOps Engineer","text":""},{"location":"about/#summary","title":"Summary","text":"<p>I'm Ramaprasad Guduru, working as a DevOps Engineer. I have experience in provisioning and managing cloud infrastructure, automating maintenance, and regular jobs on cloud infrastructure. I also have experience in handling the entire project lifecycle.</p>"},{"location":"about/#customization","title":"Customization","text":"<p>Social Media: - LinkedIn \ud83d\udcce - Instagram \ud83d\udcf8 - Facebook \ud83d\udcd8 - Site \ud83c\udf10 - Medium \u270d\ufe0f</p>"},{"location":"about/#site-is-under-maintenance","title":"(SITE IS UNDER MAINTENANCE \ud83d\udea7)","text":""},{"location":"benefitsofversioncontrol/","title":"Benefits of Version Control \ud83c\udfc3","text":""},{"location":"benefitsofversioncontrol/#benefits-of-version-control-system","title":"Benefits of Version Control System","text":"Benefit Description Change Tracking Keep track of all changes made in the project. Revert Changes Easily revert changes made in the project to previous states. Collaboration Facilitate collaboration with other developers on the project. Effective Project Management Efficiently manage and organize the project's resources. Bug Tracking Track and identify bugs or issues in the project code."},{"location":"docker/","title":"Docker \ud83d\udc33","text":""},{"location":"docker/#docker-commands","title":"Docker Commands","text":"S.No Command Description 1 <code>docker build -t &lt;image_name&gt;:&lt;tag&gt; .</code> \ud83d\udc33 Build a Docker image with the specified name and tag from the current directory (Dockerfile location). 2 <code>docker run -p &lt;host_port&gt;:&lt;container_port&gt; &lt;image_name&gt;:&lt;tag&gt;</code> \ud83c\udfc3 Run a Docker container based on the specified image, mapping a host port to a container port. 3 <code>docker ps</code> \ud83d\udccb List all running Docker containers. 4 <code>docker ps -a</code> \ud83d\udccb List all Docker containers, including stopped ones. 5 <code>docker stop &lt;container_id_or_name&gt;</code> \u23f9\ufe0f Stop a running Docker container by its ID or name. 6 <code>docker rm &lt;container_id_or_name&gt;</code> \ud83d\uddd1\ufe0f Remove a stopped Docker container by its ID or name. 7 <code>docker rmi &lt;image_name&gt;:&lt;tag&gt;</code> \ud83d\uddd1\ufe0f Remove a Docker image by its name and tag. 8 <code>docker images</code> \ud83d\udcf7 List all Docker images on your system. 9 <code>docker pull &lt;image_name&gt;:&lt;tag&gt;</code> \u2b07\ufe0f Pull a Docker image from a Docker registry. 10 <code>docker push &lt;image_name&gt;:&lt;tag&gt;</code> \u2b06\ufe0f Push a Docker image to a Docker registry. 11 <code>docker exec -it &lt;container_id_or_name&gt; &lt;command&gt;</code> \ud83d\udcbb Execute a command in a running Docker container with interactive mode. 12 <code>docker logs &lt;container_id_or_name&gt;</code> \ud83d\udcdc View the logs of a running Docker container. 13 <code>docker network ls</code> \ud83c\udf10 List all Docker networks. 14 <code>docker volume ls</code> \ud83d\udcbe List all Docker volumes. 15 <code>docker-compose up</code> \ud83d\ude80 Start services defined in a Docker Compose file. 16 <code>docker-compose down</code> \u2b07\ufe0f Stop and remove services defined in a Docker Compose file. 17 <code>docker system prune</code> \ud83e\uddf9 Remove all stopped containers, unused networks, and dangling images and volumes to free up disk space. 18 <code>docker version</code> \u2139\ufe0f Display Docker version information. 19 <code>docker info</code> \u2139\ufe0f Display Docker system-wide information. 20 <code>docker --help</code> \u2753 Display Docker help and available commands."},{"location":"flexibility/","title":"Flexibility \ud83e\udde9","text":"<p>One of the advantages provided by Git is its flexibility in several aspects:</p> <p>Track Changes - Changes can be tracked as someone making a change leaves a commit message about it.</p> <p>Backup and Restore \u2013 It helps to maintain the source code backup.</p> <p>Collaboration - It enables software team to collaborate with each other.</p> <p>Branching and Merging \u2013 Changes are made on a branch and after being approved, they can be merged with the master branch. You can see who changed the file and what parts of the content are changed.</p> <p>Deployment - It deploys the source code on the server with only one command.</p>"},{"location":"gitcommands/","title":"Git Commands \ud83d\udcdc","text":"S.No Command Description 1 <code>git init</code> Initialize a local Git repository 2 <code>git clone repo_url</code> Clone public repository 3 <code>git clone ssh://git@github.com/[username]/[repository]</code> Clone private repository 4 <code>git status</code> Check status 5 <code>git add [file-name]</code> Add a file to the staging area 6 <code>git add -A</code> Add all new and changed files to the staging area 7 <code>git commit -m \"[commit message]\"</code> Commit changes 8 <code>git rm -r [file-name.txt]</code> Remove a file (or folder) 9 <code>git branch</code> List of branches (the asterisk denotes the current branch) 10 <code>git branch -a</code> List all branches (local and remote) 11 <code>git branch [branch name]</code> Create a new branch 12 <code>git branch -d [branch name]</code> Delete a branch 13 <code>git branch -D [branch name]</code> Delete a branch forcefully 14 <code>git push origin --delete [branch name]</code> Delete a remote branch 15 <code>git checkout -b [branch name]</code> Create a new branch and switch to it 16 <code>git checkout -b [branch name] origin/[branch name]</code> Clone a remote branch and switch to it 17 <code>git branch -m [old branch name] [new branch name]</code> Rename a local branch 18 <code>git checkout [branch name]</code> Switch to a branch 19 <code>git checkout -</code> Switch to the branch last checked out 20 <code>git checkout -- [file-name.txt]</code> Discard changes to a file 21 <code>git merge [branch name]</code> Merge a branch into the active branch 22 <code>git merge [source branch] [target branch]</code> Merge a branch into a target branch 23 <code>git stash</code> Stash changes in a dirty working directory 24 <code>git stash clear</code> Remove all stashed entries 25 <code>git push origin [branch name]</code> Push a branch to your remote repository 26 <code>git push -u origin [branch name]</code> Push changes to remote repository (and remember the branch) 27 <code>git push</code> Push changes to remote repository (remembered branch) 28 <code>git push origin --delete [branch name]</code> Delete a remote branch 29 <code>git pull</code> Update local repository to the newest commit 30 <code>git pull origin [branch name]</code> Pull changes from remote repository 31 <code>git remote add origin ssh://git@github.com/[username]/[repository-name].git</code> Add a remote repository 32 <code>git remote set-url origin ssh://git@github.com/[username]/[repository-name].git</code> Set a repository's origin branch to SSH 33 <code>git log</code> View changes 34 <code>git log --summary</code> View changes (detailed) 35 <code>git log --oneline</code> View changes (briefly) 36 <code>git diff [source branch] [target branch]</code> Preview changes before merging 37 <code>git revert commitid</code> Revert commit changes 38 <code>git config --global user.name \"your_username\"</code> Set globally Username 39 <code>git config --global user.email \"your_email_address@example.com\"</code> Set globally Email id 40 <code>git config --global --list</code> Get global config"},{"location":"gitfordesigners/","title":"Git: Efficient Version Control","text":"<p>Git is a \ud83c\udd93 free and \ud83c\udf10 open-source distributed version control system designed to handle projects of all sizes, from small to very large, with \u26a1 speed and efficiency.</p>"},{"location":"gitfordesigners/#key-advantages-of-git","title":"Key Advantages of Git","text":"<p>Git stands out for several reasons:</p> <p>\ud83d\udcda Ease of Learning: Git is known for its user-friendly interface and is easy to learn. It's a version control system that doesn't require a steep learning curve.</p> <p>\ud83c\udfc3 Lightning-Fast Performance: Git boasts a tiny footprint and operates with \u26a1 lightning-fast performance. You won't experience delays when working with your projects.</p> <p>\ud83c\udf3f Efficient Branching: Git offers convenient and cost-effective local branching. Developers can create branches without significant overhead, making it easy to work on multiple features or fixes simultaneously.</p> <p>\ud83e\udde9 Convenient Staging Areas: Git includes a staging area where you can prepare changes before committing them. This allows for a more organized and structured development process.</p> <p>\ud83d\udd04 Multiple Workflows: Git supports various workflows, allowing teams to choose the one that best suits their needs. Whether it's centralized, feature branching, or Gitflow, Git can accommodate your workflow.</p>"},{"location":"gitfordesigners/#git-vs-other-scm-tools","title":"Git vs. Other SCM Tools","text":"<p>Git outclasses other source code management (SCM) tools like Subversion, CVS, Perforce, and ClearCase due to its remarkable advantages. It's the go-to choice for developers worldwide.</p>"},{"location":"gitfordesigners/#collaborative-development","title":"Collaborative Development","text":"<p>Git facilitates collaboration among developers and teams:</p> <p>\ud83e\udd1d Branching and Merging: Git makes it easy for developers to create branches for new features or bug fixes. Merging these changes back into the main codebase is seamless.</p> <p>\ud83d\udd17 Remote Repositories: Git supports remote repositories, making it possible for teams to work together from different locations. Services like GitHub, GitLab, and Bitbucket provide excellent platforms for remote collaboration.</p> <p>\ud83d\udd04 Version History: Git tracks every change made to your codebase, providing a detailed version history. This history includes who made the changes and when, making it easy to understand the evolution of your project.</p>"},{"location":"gitfordesigners/#distributed-nature","title":"Distributed Nature","text":"<p>Git's distributed nature offers unique benefits:</p> <p>\ud83d\udd17 No Single Point of Failure: Every developer has a complete copy of the repository, reducing the risk of data loss. If one server fails, there are backups.</p> <p>\ud83d\udd12 Security: Git ensures data integrity and prevents unauthorized changes through cryptographic hashing.</p>"},{"location":"gitfordesigners/#supporting-tools","title":"Supporting Tools","text":"<p>Git is often complemented by a range of tools and services:</p> <p>\ud83d\udda5\ufe0f GitHub: A popular web-based platform for hosting Git repositories, facilitating collaboration, and managing projects.</p> <p>\ud83d\udc19 GitLab: A web-based platform similar to GitHub, offering additional features for CI/CD and container registry.</p> <p>\ud83e\udeb6 Bitbucket: Another web-based platform for Git repositories, with strong support for integration and team collaboration.</p>"},{"location":"gitfordesigners/#conclusion","title":"Conclusion","text":"<p>Git empowers developers and teams to efficiently manage their codebase, collaborate seamlessly, and ensure the integrity and security of their projects. Whether you're working on a small project or a massive endeavor, Git is your reliable version control companion.</p> <p>Get started with Git today and experience the benefits of a version control system designed for speed, efficiency, and collaboration!</p>"},{"location":"linux/","title":"Linux \ud83d\udc27","text":"Commands Description <code>cat [filename]</code> Display file\u2019s contents to the standard output device <code>cd /directorypath</code> Change to directory <code>chmod [options] mode filename</code> Change a file\u2019s permissions <code>chown [options] filename</code> Change who owns a file <code>clear</code> Clear a command line screen/window for a fresh start. <code>cp [options] source destination</code> Copy files and directories. <code>date [options]\"</code> Display or set the system date and time. <code>df [options]</code> Display used and available disk space. <code>du [options]</code> Show how much space each file takes up. <code>file [options] filename</code> Determine what type of data is within a file. <code>find [pathname] [expression]</code> Search for files matching a provided pattern. <code>grep [options] pattern [filesname]</code> Search files or output for a particular pattern. <code>kill [options] pid</code> Stop a process. If the process refuses to stop, use kill -9 pid. <code>less [options] [filename]</code> View the contents of a file one page at a time. <code>ln [options] source [destination]</code> Create a shortcut. <code>locate filename</code> Search a copy of your filesystem for the specified filename. <code>lpr [options]</code> Send a print job. <code>ls [options]</code> List directory contents. <code>man [command]</code> Display the help information for the specified command. <code>mv [options] source destination</code> Rename or move file(s) or directories. <code>passwd [name [password]]</code> Change the password or allow (for the system administrator) to change any password. <code>ps [options]</code> Display a snapshot of the currently running processes. <code>pwd</code> Display the pathname for the current directory. <code>rm [options] directory</code> Remove (delete) file(s) and/or directories. <code>rmdir [options] directory</code> Delete empty directories. <code>su [options] [user [arguments]]</code> Remotely log in to another Linux machine, over the network. Leave an ssh session by typing exit. <code>tail [options] [filename]</code> Display the last n lines of a file (the default is 10). <code>tar [options] filename</code> Store and extract files from a tarfile (.tar) or tarball (.tar.gz or .tgz). <code>top</code> Displays the resources being used on your system. Press q to exit. <code>touch filename</code> Create an empty file with the specified name. <code>who [options]</code> Display who is logged on."},{"location":"mon/","title":"Monitoring &amp; Dashboard","text":""},{"location":"mon/#table-of-contents","title":"Table of Contents:","text":"<ol> <li> <p>High-level monitoring architecture and Flow diagram</p> </li> <li> <p>Purpose\u00a0</p> </li> <li> <p>Powerapps Monitoring\u00a0</p> </li> <li> <p>\u200bMetrics\u00a0</p> </li> <li> <p>\u200bLogs\u00a0</p> </li> <li> <p>\u200bAlerts \u00a0</p> </li> <li> <p>\u200bDashboards \u00a0</p> </li> <li> <p>\u200bUser activity metrics\u00a0</p> </li> <li> <p>\u200bApp performance metrics\u00a0</p> </li> <li> <p>\u200bData usage metrics\u00a0</p> </li> <li> <p>\u200bFlow and Power Automate metrics\u00a0</p> </li> <li> <p>\u200bCustom connector metrics\u00a0 \u200b\u00a0</p> </li> <li> <p>Azure Resources</p> </li> <li> <p>\u200bVirtual Machines \u00a0</p> </li> <li> <p>\u200bAzure App Service (Web Apps, Mobile Apps, API Apps)\u00a0</p> </li> <li> <p>\u200bAzure Storage (Blobs, Queues, Tables, Files)\u00a0</p> </li> <li> <p>\u200bAzure Cosmos DB\u00a0</p> </li> <li> <p>App Registration</p> </li> <li> <p>App Configuration</p> </li> <li> <p>\u200bAzure Functions\u00a0</p> </li> <li> <p>\u200bAzure Active Directory\u00a0</p> </li> <li> <p>\u200bAzure Service Bus (Queues, Topics)\u00a0</p> </li> <li> <p>Azure DevOps</p> </li> <li> <p>\u200bWork item tracking metrics\u00a0</p> </li> <li> <p>\u200bAzure Devops repository metrics\u00a0</p> </li> <li> <p>\u200bBuild metrics\u00a0</p> </li> <li> <p>\u200bRelease metrics\u00a0</p> </li> <li> <p>\u200bTestplan metrics\u00a0</p> </li> <li> <p>\u200bResource utilization metrics\u00a0</p> </li> <li> <p>\u200bAzure Artifacts\u00a0</p> </li> </ol>"},{"location":"mon/#high-level-monitoring-architecture","title":"High-Level Monitoring Architecture","text":""},{"location":"mon/#high-level-monitoring-flow-diagram","title":"High-Level Monitoring Flow Diagram","text":"<p>image</p>"},{"location":"mon/#process-to-send-notification-for-azure-resources","title":"Process to Send Notification For Azure Resources","text":""},{"location":"mon/#purpose","title":"Purpose","text":"<p>The purpose of monitoring PowerApps, Azure, and Azure DevOps using Azure Monitor or Insights is to gain insights into the performance, availability, and security of these critical systems and applications. Here are some specific benefits of using Azure Monitor or Insights for monitoring \u00a0</p> <p>\u200bPowerApps Monitoring: PowerApps is a low-code platform that enables users to create custom business applications without writing code. Monitoring PowerApps with Azure Monitor or Insights can help identify issues that could impact application performance, such as long response times or errors, and optimize app performance.</p> <p>\u200bAzure Monitoring: Azure is a cloud computing platform that provides a wide range of services for building, deploying, and managing applications and services. Monitoring Azure services with Azure Monitor or Insights can help detect and troubleshoot issues across the entire stack, including virtual machines, containers, storage, and networking.</p> <p>\u200bAzure DevOps Monitoring: Azure DevOps is a cloud-based service that provides tools for software development, testing, and deployment. Monitoring Azure DevOps with Azure Monitor or Insights can help ensure that DevOps processes are running smoothly, identify bottlenecks and optimize processes, and track deployment success rates.In general, using Azure Monitor or Insights for monitoring provides a centralized platform for collecting and analyzing data from multiple sources, enabling organizations to gain a holistic view of their systems and applications. By monitoring and analyzing this data, organizations can proactively identify and address issues before they become\u00a0critical, optimize system performance and resource utilization, and ensure the reliability, security, and availability of their critical systems and applications.</p> <p>\u200bHere are the Power Apps tenants and environments level monitoring supported by Azure Monitor</p> <p>Power Apps production and non-production environments</p> <p>\u200b1. Power Apps portals\u00a0</p> <p>\u200b2. PowerApps Common Data Service (CDS) environments\u00a0</p>"},{"location":"mon/#azure-monitor-provides-the-following-types-of-monitoring-for-powerapps-environments","title":"Azure Monitor provides the following types of monitoring for PowerApps environments:","text":"<p>\u200b1. Metrics - Azure Monitor collects metrics for various resources within a PowerApps environment, such as portal page views, CDS entities, and more. These metrics can be used to creat*e custom alerts and dashboards.\u00a0</p> <p>2. Logs - Azure Monitor can collect logs from various sources within a PowerApps environment, such as portal requests, audit logs, and more. These logs can be used for troubleshooting and analysis.\u00a0</p> <p>\u200b3. Alerts - Azure Monitor can create alerts based on speci\ufb01c conditions in your PowerApps environment, such as when a portal page is unavailable or when a certain number of CDS requests fail.</p> <p>4. Dashboards - Azure Monitor can create custom dashboards that provide a visual representation of metrics and logs from your PowerApps environment. These dashboards can be customized to show the information that is most important.\u00a0</p> <p>\u200bMetrics for PowerApps: </p> <p>\u200b1. Portal page views - the number of views for each portal page.\u00a0</p> <p>\u200b2. Portal unique visitors - the number of unique visitors to a portal.\u00a0</p> <p>\u200b3. Portal requests - the number of requests made to a portal.\u00a0</p> <p>\u200b4. Portal response time - the time it takes for a portal to respond to a request.\u00a0</p> <p>\u200b5. Portal user login failures - the number of failed login attempts by portal users.\u00a0</p> <p>\u200b6. CDS entity reads - the number of times a CDS entity is read.\u00a0</p> <p>\u200b7. CDS entity writes - the number of times a CDS entity is written to.\u00a0</p> <p>\u200b8. CDS entity deletes - the number of times a CDS entity is deleted.\u00a0</p> <p>\u200b9. CDS API calls - the number of API calls made to CDS.\u00a0</p> <p>\u200b10. CDS failed requests - the number of failed requests made to CDS.\u00a0</p> <p>These metrics can be used to gain insights into the performance and usage of your PowerApps environment. You can use Azure Monitor to create custom alerts based on these metrics to be noti\ufb01ed when certain thresholds are reached. You can also create custom dashboards to visualize these metrics and gain a better understanding of your PowerApps environment.\u00a0</p>"},{"location":"mon/#azure-monitor-and-azure-insights","title":"Azure Monitor and Azure Insights:","text":"<p>\u200bUser activity metrics </p> <p>\u200b\u25cf Number of active users\u00a0</p> <p>\u25cf Active user trends over time\u00a0</p> <p>\u200b\u25cf Number of unique sessions\u00a0</p> <p>\u200b\u25cf Session duration and frequency\u00a0</p> <p>\u200b\u25cf Popular apps and screen\u00a0</p>"},{"location":"mon/#app-performance-metrics","title":"\u200bApp performance metrics","text":"<p>\u200b\u25cf App load times\u00a0</p> <p>\u200b\u25cf App response times\u00a0</p> <p>\u200b\u25cf App crashes and error rates\u00a0</p> <p>\u200b\u25cf Resource utilization (CPU, memory, disk)\u00a0</p> <p>\u200b\u25cf API call duration and frequency\u00a0</p>"},{"location":"mon/#data-usage-metrics","title":"\u200bData usage metrics","text":"<p>\u200b\u25cf Number of data requests\u00a0</p> <p>\u200b\u25cf Data request trends over time\u00a0</p> <p>\u200b\u25cf Data request response times\u00a0\u200b\u00a0</p> <p>\u200b\u25cf Data usage by app and user\u00a0</p> <p>\u200b\u25cf Data usage by data source and entity\u00a0</p>"},{"location":"mon/#flow-and-power-automate-metrics","title":"\u200bFlow and Power Automate metrics","text":"<p>\u200b\u25cf Number of successful and failed runs\u00a0</p> <p>\u200b\u25cf Run duration and frequency\u00a0</p> <p>\u200b\u25cf Flow response times\u00a0</p> <p>\u200b\u25cf Number of triggers and actions\u00a0</p> <p>\u200b\u25cf Flow and Power Automate errors and exceptions\u00a0</p>"},{"location":"mon/#custom-connector-metrics","title":"Custom connector metrics","text":"<p>\u200b\u25cf Connector usage and adoption\u00a0</p> <p>\u200b\u25cf Connector response times\u00a0</p> <p>\u200b\u25cf Connector error rates\u00a0</p> <p>\u200b\u25cf Custom connector performance metrics\u00a0</p> <p>\u200b\u25cf Connector authorization and authentication metrics\u00a0</p> <p>\u200b\u00a0</p>"},{"location":"mon/#azure-resources","title":"Azure Resources","text":"<p>\u200bHere is a list of some of the metrics and data that can be monitored for each of the Azure resources using Azure Monitor</p> <p>\u200b1. Virtual Machines </p> <p>\u200b\u25cf CPU usage\u00a0</p> <p>\u200b\u25cf Memory usage\u00a0</p> <p>\u200b\u25cf Disk I/O\u00a0</p> <p>\u200b\u25cf Network tra\ufb03c\u00a0</p> <p>\u200b\u25cf Disk space utilization\u00a0</p> <p>\u200b\u25cf Disk read/write operations\u00a0</p> <p>\u200b\u25cf Operating system performance counters\u00a0</p> <p>2.Azure App Service (Web Apps, Mobile Apps, API Apps) </p> <p>\u200b\u25cf Response time\u00a0</p> <p>\u200b\u25cf CPU usage\u00a0</p> <p>\u200b\u25cf Memory usage\u00a0</p> <p>\u200b\u25cf HTTP status codes\u00a0</p> <p>\u200b\u25cf Requests per second\u00a0</p> <p>\u200b\u25cf Exceptions and errors\u00a0</p> <p>\u200b\u25cf Performance counters from the underlying VM\u00a0</p> <p>\u200b\u25cf Performance counters from the underlying VM3.\u00a0</p> <p>\u200b3. Azure Storage (Blobs, Queues, Tables, Files) </p> <p>\u200b\u25cf Data ingress/egress\u00a0</p> <p>\u200b\u25cf Transaction rates\u00a0</p> <p>\u200b\u25cf Latency\u00a0</p> <p>\u200b\u25cf Capacity and utilization\u00a0</p> <p>\u200b\u25cf Availability\u00a0</p> <p>\u200b\u25cf Failure events\u00a0</p> <p>\u200b\u200b4. Azure Event Hubs </p> <p>\u200b\u25cf Incoming events\u00a0</p> <p>\u200b\u25cf Outgoing events\u00a0</p> <p>\u200b\u25cf Incoming bytes\u00a0</p> <p>\u200b\u25cf Incoming and outgoing rates\u00a0</p> <p>\u200b\u25cf Connection errors\u00a0</p> <p>\u200b\u25cf Availability\u00a0</p> <p>5. Azure Cosmos DB </p> <p>\u200b\u25cf Request units (RUs)\u00a0</p> <p>\u200b\u25cf Storage usage\u00a0</p> <p>\u200b\u25cf Availability\u00a0</p> <p>\u200b\u25cf Throughput\u00a0</p> <p>\u200b\u25cf Latency\u00a0</p> <p>\u200b\u25cf Failed requests\u00a0</p> <p>6. Azure App Registration</p> <p>\u200b\u25cf Authentication Latency: Measures the time it takes to authenticate a user or service principal with Azure AD.  </p> <p>\u25cf Failed Authentication Requests: Counts the number of failed authentication requests to Azure AD. </p> <p>\u25cf Successful Authentication Requests: Counts the number of successful authentication requests to Azure AD. </p> <p>\u25cf API Call Rate: Measures the number of API calls per minute or per hour.  </p> <p>\u25cf API Response Time: Measures the time it takes for an API request to return a response. </p> <p>\u25cf Application Errors: Counts the number of application errors, including failed requests and exceptions.</p> <p>\u200b\u25cf Memory Usage: Measures the amount of memory used by the application.  </p> <p>\u25cf CPU Usage: Measures the percentage of CPU usage by the application.</p> <p>\u200b\u25cf Network Traffic: Measures the amount of inbound and outbound network traffic for the application.</p> <p>\u200b\u25cf Response Time: Measures the time it takes for the application to respond to a request.</p> <p>7. Azure App configuration</p> <p>\u200b\u25cf Configuration Changes: Counts the number of configuration changes made within a specified time period.</p> <p>\u200b\u25cf Configuration Latency: Measures the time it takes to fetch or update a configuration setting.</p> <p>\u200b\u25cf Connection Failures: Counts the number of failed connections to Azure App Configuration.</p> <p>\u200b\u25cf Queries per Second: Measures the number of configuration queries per second.</p> <p>\u200b\u25cf Key or Value Size: Measures the size of keys or values stored in Azure App Configuration.</p> <p>\u200b\u25cf Throttled Requests: Counts the number of requests that have been throttled due to exceeding the service limits.</p> <p>\u200b\u25cf Data Volume: Measures the amount of data stored in Azure App Configuration.</p> <p>\u200b\u25cf Application Errors: Counts the number of application errors related to Azure App Configuration.</p> <p>\u200b\u25cf Response Time: Measures the time it takes for Azure App Configuration to respond to a request.</p> <p>\u200b\u25cf Throughput: Measures the number of requests per second processed by Azure App Configuration.</p> <p>\u200b7. Azure Functions </p> <p>\u200b\u25cf Execution count\u00a0</p> <p>\u200b\u25cf Execution duration\u00a0</p> <p>\u200b\u25cf Failed invocations\u00a0</p> <p>\u200b\u25cf CPU usage\u00a0</p> <p>\u200b\u25cf Memory usage\u00a0</p> <p>\u200b\u25cf Network tra\ufb03c\u00a0</p> <p>\u200b8. Azure Active Directory </p> <p>\u200b\u25cf Sign-ins and sign-outs\u00a0</p> <p>\u200b\u25cf Authentication and authorization errors\u00a0</p> <p>\u200b\u25cf Role assignments and changes\u00a0</p> <p>\u200b\u25cf Directory object changes\u00a0</p> <p>9. Azure Service Bus (Queues, Topics) </p> <p>\u200b\u25cf Message ingress/egress\u00a0</p> <p>\u200b\u25cf Queue/topic size and backlog\u00a0</p> <p>\u200b\u25cf Active and dead-letter message counts\u00a0</p> <p>\u200b\u25cf Connection errors\u00a0</p> <p>\u200b\u25cf Availability\u00a0</p> <p>10. Azure KeyVault</p> <p>\u200b\u25cf Secret Access Count: Counts the number of times a secret has been accessed within a specified time period.</p> <p>\u200b\u25cf Key Access Count: Counts the number of times a key has been accessed within a specified time period.</p> <p>\u200b\u25cf Certificate Access Count: Counts the number of times a certificate has been accessed within a specified time period.</p> <p>\u200b\u25cf Encryption and Decryption Operations: Counts the number of encryption and decryption operations performed within a specified time period.</p> <p>\u200b\u25cf Key Vault Latency: Measures the time it takes to fetch or update a secret, key, or certificate in Azure Key Vault.</p> <p>\u200b\u25cf Failed Operations: Counts the number of failed operations within a specified time period.</p> <p>\u200b\u25cf Network Traffic: Measures the amount of inbound and outbound network traffic for Azure Key Vault.</p> <p>\u200b\u25cf Request Latency: Measures the time it takes for Azure Key Vault to respond to a request.</p> <p>\u200b\u25cf Unauthorized Access Attempts: Counts the number of unauthorized access attempts to Azure Key Vault.</p> <p>\u200b\u25cf Authentication Errors: Counts the number of authentication errors related to Azure Key Vault.</p>"},{"location":"mon/#azure-devops-monitoring","title":"\u200bAzure DevOps Monitoring","text":"<p>\u200bWork item tracking metrics </p> <p>\u200b\u25cf Work item cycle time\u00a0</p> <p>\u200b\u25cf Work item lead time\u00a0</p> <p>\u200b\u25cf Work item backlog size\u00a0</p> <p>\u200b\u25cf Work item completion rate\u00a0</p> <p>\u200b\u25cf Bug resolution rates\u00a0</p> <p>\u200b\u25cf Feature delivery rate\u00a0</p> <p>Azure Devops repository metrics </p> <p>\u200b\u25cf Number of commits\u00a0</p> <p>\u200b\u25cf Number of pull requests\u00a0</p> <p>\u200b\u25cf Merge success and failure rates\u00a0</p> <p>\u200b\u25cf Merge times and durations\u00a0</p> <p>\u200b\u25cf Number of branches and tags\u00a0</p> <p>\u200b\u25cf Commit and merge frequency\u00a0</p> <p>Build metrics </p> <p>\u200b\u25cf Build success and failure rates\u00a0</p> <p>\u25cf Build times and durations\u00a0</p> <p>\u200b\u25cf Queue time for builds\u00a0</p> <p>\u200b\u25cf Average queue length\u00a0</p> <p>\u200b\u25cf Number of builds in progress\u00a0</p> <p>\u200b\u25cf Number of builds waiting in the queue\u00a0</p> <p>\u200b\u25cf Number of builds triggered by branch or commit\u00a0</p> <p>\u200b \u200bRelease metrics </p> <p>\u200b\u25cf Release success and failure rates\u00a0</p> <p>\u200b\u25cf Release times and durations\u00a0</p> <p>\u200b\u25cf Deployment frequency\u00a0</p> <p>\u200b\u25cf Time to deploy\u00a0</p> <p>\u200b\u25cf Average wait time for releases\u00a0</p> <p>\u200b\u25cf Number of releases in progress\u00a0</p> <p>\u200b\u25cf Number of releases waiting in the queue\u00a0</p> <p>Testplan metrics </p> <p>\u25cf Test pass/fail rates\u00a0</p> <p>\u200b\u25cf Test case coverage\u00a0</p> <p>\u200b\u25cf Test execution times\u00a0</p> <p>\u200b\u25cf Test result distribution\u00a0</p> <p>\u200b\u25cf Test suite duration\u00a0</p> <p>\u200bResource utilization metrics </p> <p>\u200b\u25cf CPU and memory usage for Azure DevOps agents and build servers\u00a0</p> <p>\u200b\u25cf Disk space usage\u00a0</p> <p>\u200b\u25cf Network usage\u00a0</p> <p>\u200b\u25cf Connection time and rate\u00a0</p> <p>\u200bAzure Artifacts </p> <p>\u200bHere is the Metrics related to Azure DevOps Artifacts that can be collected and analyzed using Azure Monitor and Insights</p> <p>\u200bPackage download metrics </p> <p>\u200b\u25cf Number of package downloads\u00a0</p> <p>\u200b\u25cf Package download rates\u00a0</p> <p>\u200b\u25cf Average download size per package\u00a0</p> <p>\u200b\u25cf Package download time\u00a0</p> <p>\u200b\u25cf Top downloaders by IP address, user, or client\u00a0</p> <p>\u200b \u200bPackage publish metrics </p> <p>\u200b\u25cf Number of package publishes\u00a0</p> <p>\u200b\u25cf Package publish rates\u00a0</p> <p>\u200b\u25cf Average publish size per package\u00a0</p> <p>\u200b\u25cf Package publish time\u00a0</p> <p>\u200b\u25cf Top publishers by IP address, user, or client\u00a0</p> <p>Package retention metrics </p> <p>\u200b\u25cf Number of packages retained\u00a0</p> <p>\u200b\u25cf Retention rate\u00a0</p> <p>\u200b\u25cf Retention time\u00a0</p> <p>\u200b\u25cf Number of packages deleted\u00a0</p> <p>\u200b\u25cf Deletion rates\u00a0</p> <p>\u200b\u25cf Average time to deletion\u00a0</p> <p>Package security metrics </p> <p>\u200b\u25cf Vulnerability scan results\u00a0</p> <p>\u200b\u25cf Security alerts and noti\ufb01cations\u00a0</p> <p>\u200b\u25cf Number of packages with security issues\u00a0</p> <p>\u200b\u25cf Package access and permission control\u00a0</p>"},{"location":"mon/#here-are-some-alert-threshold-values-for-commonly-monitored-azure-resources","title":"Here are some alert threshold values for commonly monitored Azure resources:","text":"<p>Virtual Machines:</p> <pre><code>\u2022 CPU Usage: Alert threshold could be set to 80% for a sustained period of time.\n\n\u2022 Memory Usage: Alert threshold could be set to 80% for a sustained period of time.\n\n\u2022 Disk Space Usage: Alert threshold could be set to 85% for a sustained period of time.\n\n\u2022 Network Usage: Alert threshold could be set to 80% for a sustained period of time.\n\n\u2022 Disk IOPS: Alert threshold could be set to 90% for a sustained period of time.\n</code></pre> <p>Azure App Service:</p> <pre><code>\u2022 CPU Utilization: 80% for sustained periods of time\n\n\u2022 Memory Utilization: 80% for sustained periods of time\n\n\u2022 HTTP 5xx error rate: 5% for sustained periods of time\n\n\u2022 HTTP 4xx error rate: 10% for sustained periods of time\n</code></pre> <p>Azure Storage:</p> <pre><code>\u2022 Queue Length: 1,000 for more than 5 minutes\n\n\u2022 Blob Capacity: 80% for sustained periods of time\n\n\u2022 Transaction Rate: 80% for sustained periods of time\n\n\u2022 Egress Bandwidth: 80% for sustained periods of time\n</code></pre> <p>Azure Functions:</p> <pre><code>\u2022 Execution Count: 100,000 within an hour\n\n\u2022 Average Execution Time: 5 seconds or greater\n\n\u2022 Memory Usage: 70% for sustained periods of time\n\n\u2022 Exception Count: 100 within an hour\n\n\u2022 HTTP 5xx Error Rate: 5% for sustained periods of time\n</code></pre> <p>Azure App Configuration:</p> <pre><code>\u2022 Configuration Changes: 10 configuration changes per hour\n\n\u2022 Configuration Latency: 500 milliseconds for fetch or update operations\n\n\u2022 Connection Failure: 5 connection failures per hour\n\n\u2022 Queries per Second: 100 configuration queries per second\n\n\u2022 Key or Value Size: Maximum key or value size of 1 MB\n</code></pre> <p>Azure Event Hubs:</p> <pre><code>\u2022 Incoming Messages: Alert threshold could be set to a specific number or rate of messages within a defined time period, such as 100,000 messages in 1 hour.\n\n\u2022 Outgoing Messages: Alert threshold could be set to a specific number or rate of messages within a defined time period, such as 50,000 messages in 30 minutes.\n\n\u2022 Active Connections: Alert threshold could be set to a specific number of active connections, such as 500 connections.\n\n\u2022 Throttled Requests: Alert threshold could be set to the number of requests that have been throttled, such as 500 requests in 1 hour.\n\n\u2022 Latency: Alert threshold could be set to a specific response time or average latency value, such as 500ms response time for incoming messages.\n</code></pre> <p>Azure Active Directory</p> <pre><code>\u2022 Failed Sign-In Attempts: Alert threshold could be set to a specific number of failed sign-in attempts within a defined time period, such as 10 failed attempts in 1 hour.\n\n\u2022 Password Resets: Alert threshold could be set to the number of password resets within a defined time period, such as 50 resets in 24 hours.\n\n\u2022 User Account Deletion: Alert threshold could be set to the number of user accounts deleted within a defined time period, such as 5 accounts in 1 day.\n\n\u2022 Multi-Factor Authentication: Alert threshold could be set to the number of successful or unsuccessful MFA attempts, such as 100 successful or unsuccessful attempts in 1 hour.\n\n\u2022 Directory Role Changes: Alert threshold could be set to the number of directory role changes, such as 10 changes in 1 hour.\n</code></pre> <p>Azure keyvault ``` \u2022  Key Vault Expiration: Set an alert threshold value to notify when a certificate, key or secret is about to expire, such as 30 days or 60 days before the expiration date.</p> <p>\u2022  Key Vault Access: Set an alert threshold value to notify when there is an unusual amount of access to your Key Vault, such as more than 10 requests per second.</p> <p>\u2022  Key Vault Authentication: Set an alert threshold value to notify when there is an unusual amount of authentication failures, such as more than 5 failed attempts in 1 hour.</p> <p>\u2022  Key Vault Errors: Set an alert threshold value to notify when there is an unusual amount of errors, such as more than 10 errors per minute.</p> <p>\u2022  Key Vault Latency: Set an alert threshold value to notify when there is an unusual amount of latency, such as more than 100 milliseconds for each request.</p> <p>```</p>"},{"location":"mon/#who-should-receive-azure-resources-alert-notifications","title":"Who should receive Azure Resources alert notifications","text":"<ul> <li> <p>Virtual Machines: Notifications can be sent to the DevOps team,     IT administrators, or security team.</p> </li> <li> <p>Azure App Service: Notifications can be sent to the     development team, operations team, or project managers.</p> </li> <li> <p>Azure Storage: Notifications can be sent to the operations     team, IT administrators, or security team.</p> </li> <li> <p>Azure Virtual Network: Notifications can be sent to the     network administrators, security team, or IT administrators.</p> </li> <li> <p>Azure Key Vault: Notifications can be sent to the security     team, operations team, or DevOps team.</p> </li> <li> <p>Azure Functions: Notifications can be sent to the DevOps     team, development team, or project managers. They can be related to     issues with the Azure Functions service, such as errors in function     execution, function timeouts, or issues with function triggers.</p> </li> <li> <p>Azure Service Bus: Notifications can be sent to the     operations team, IT administrators, or security team. They can be     related to issues with the Service Bus service, such as message     delivery failures, connectivity issues, or issues with authorization     and access control.</p> </li> <li> <p>Azure Event Grid: Notifications can be sent to the DevOps     team, development team, or project managers. They can be related to     issues with the Event Grid service, such as event subscription     failures, event delivery issues, or issues with event schema     validation.</p> </li> <li> <p>Azure Notification Hubs: Notifications can be sent to the     operations team, IT administrators, or security team. They can be     related to issues with the Notification Hubs service, such as     message delivery failures, connectivity issues, or issues with     authorization and access control.</p> </li> <li> <p>Azure App Registration: Notifications can be sent to the     security team, operations team, or DevOps team. They can be related     to issues with App Registration, such as application authentication     failures, changes to application permissions, or changes to     application owners and contributors.</p> </li> <li> <p>Azure App Configuration: Notifications can be sent to the     development team, operations team, or project managers. They can be     related to issues with App Configuration, such as changes to     configuration settings, changes to feature flags, or issues with     configuration data consistency and integrity.</p> </li> </ul> <p>Cosmosdb:</p> <ul> <li> <p>Database administrators: If there is an alert related to     database performance or availability, the database administrator(s)     should receive the alert notification.</p> </li> <li> <p>Developers: If there is an alert related to application     performance or errors, the developers responsible for the     application should receive the alert notification.</p> </li> <li> <p>IT Operations: If there is an alert related to infrastructure or     network issues, the IT operations team should receive the alert     notification.</p> </li> <li> <p>Security personnel: If there is an alert related to security     events or breaches, the security personnel should receive the alert     notification.</p> </li> </ul>"},{"location":"mon/#who-should-receive-azure-devops-alert-notifications","title":"Who should receive Azure DevOps alert notifications","text":"<ul> <li> <p>Project administrators: If there is an alert related to project     settings, permissions, or access in Azure DevOps, the project     administrators should receive the alert notification.</p> </li> <li> <p>Developers: If there is an alert related to build or release     failures, code quality issues, or code changes in Azure DevOps, the     developers responsible for the code should receive the alert     notification.</p> </li> <li> <p>IT Operations: If there is an alert related to infrastructure or     network issues affecting the Azure DevOps service, the IT operations     team should receive the alert notification.</p> </li> <li> <p>Security personnel: If there is an alert related to security     events or breaches in Azure DevOps, the security personnel should     receive the alert notification.</p> </li> <li> <p>Testers: If there is an alert related to test failures or issues     in Azure DevOps, the testers responsible for the tests should     receive the alert notification.</p> </li> <li> <p>Scrum masters or Agile coaches: If there is an alert related to     the progress or status of a sprint or agile project in Azure DevOps,     the scrum masters or agile coaches should receive the alert     notification.</p> </li> <li> <p>Product owners or stakeholders: If there is an alert related to     a change or update in a product or feature in Azure DevOps, the     product owners or stakeholders should receive the alert     notification.</p> </li> <li> <p>Support team: If there is an alert related to customer-reported     issues or bugs in Azure DevOps, the support team should receive the     alert notification.</p> </li> <li> <p>Operations team: If there is an alert related to server or     application monitoring, the operations team should receive the alert     notification.</p> </li> <li> <p>Database administrators: If there is an alert related to     database performance, capacity, or availability issues in Azure     DevOps, the database administrators should receive the alert     notification.</p> </li> <li> <p>Business analysts: If there is an alert related to data     analytics, insights or reporting in Azure DevOps, the business     analysts should receive the alert notification.</p> </li> <li> <p>Compliance team: If there is an alert related to compliance     violations or issues in Azure DevOps, the compliance team should     receive the alert notification.</p> </li> <li> <p>Disaster recovery team: If there is an alert related to disaster     recovery, backup or restore issues in Azure DevOps, the disaster     recovery team should receive the alert notification</p> </li> <li> <p>Incident response team: If there is an alert related to security     or operational incidents in Azure DevOps, the incident response team     should receive the alert notification.</p> </li> </ul>"},{"location":"mon/#who-should-receive-powerapps-tenant-or-environmrnts-alert-notifications","title":"Who should receive PowerApps tenant or Environmrnts alert notifications","text":"<ul> <li> <p>PowerApps administrators: If there is an alert related to     the availability or performance of the PowerApps service, the     PowerApps administrators should receive the alert notification.</p> </li> <li> <p>Developers: If there is an alert related to custom code or     functionality in PowerApps, the developers responsible for the code     should receive the alert notification.</p> </li> <li> <p>IT Operations: If there is an alert related to infrastructure or     network issues affecting the PowerApps service, the IT operations     team should receive the alert notification.</p> </li> <li> <p>Security personnel: If there is an alert related to security     events or breaches in PowerApps, the security personnel should     receive the alert notification.</p> </li> </ul> <p>How to Integrate alerts for all Azure resources.</p> <p>Here are the high-level steps to integrate alerts for all Azure resources using Azure Monitor:</p> <p>Create an Azure Monitor resource: First, you need to create an Azure Monitor resource in your Azure subscription. This resource acts as a central repository for all your monitoring data.</p> <p>Enable Azure Monitor on all resources: Next, you need to enable Azure Monitor on all Azure resources that you want to monitor. This can be done using Azure Policy or by using Azure Resource Manager templates.</p> <p>Configure data sources: Once you have enabled Azure Monitor on all resources, you can configure the data sources that you want to monitor. This can include Azure resources like virtual machines, Azure App Service, Azure Storage, Azure SQL, and many others.</p> <p>Create alerts: After configuring the data sources, you can create alerts that are triggered based on certain conditions or thresholds. For example, you can create an alert that triggers when the CPU usage of a virtual machine exceeds a certain percentage.</p> <p>Define alert criteria: You can define the criteria for when an alert should be triggered, such as thresholds, time periods, and severity levels.</p> <p>Configure notification channels: Finally, you can configure notification channels for your alerts, such as email, SMS, or webhook. This ensures that the right people are notified when an alert is triggered.</p> <p>Customize alerts: Azure Monitor allows you to customize alerts by defining complex conditions, using log queries, and creating multi-dimensional alerts that combine different metrics and data sources.</p> <p>Analyze alert data: Azure Monitor provides rich analytics capabilities that allow you to analyze alert data, identify trends, and gain insights into your Azure environment. You can use log queries, visualizations, and machine learning algorithms to analyze your data and optimize your alert configuration.</p> <p>Automate remediation: Azure Monitor also allows you to automate remediation actions, such as restarting a virtual machine, scaling out an application, or executing a runbook in Azure Automation. By automating remediation, you can minimize downtime and reduce the impact of issues on your applications and services.</p> <p>Monitor third-party services: Azure Monitor can also be used to monitor third-party services and applications running outside of Azure. This can be done by integrating Azure Monitor with external monitoring solutions, such as Nagios or Zabbix, or by using Azure Monitor\\'s extensibility framework to create custom monitoring solutions.</p>"},{"location":"mon/#how-to-integrate-alerts-for-powerapps-tenants-environments-and-dataverse","title":"How to Integrate alerts for Powerapps Tenants, Environments and dataverse","text":"<ol> <li> <p>Log in to the Power Platform Admin center (https://admin.powerplatform.microsoft.com) with your admin credentials.</p> </li> <li> <p>From the left-hand navigation pane, select \\\"Environments\\\".</p> </li> <li> <p>Select the environment that you want to configure alerts for.</p> </li> <li> <p>Click on \\\"Settings\\\" in the top menu bar, and select \\\"Alerts\\\" from the dropdown menu.</p> </li> <li> <p>Click on \\\"Add alert rule\\\" to create a new alert rule.</p> </li> <li> <p>In the \\\"Add alert rule\\\" dialog box, enter a name for the alert rule, and select the severity level for the alert.</p> </li> <li> <p>Choose the type of resource you want to monitor by selecting the appropriate option from the \\\"Resource type\\\" dropdown list. You can choose from Power Apps, Power Automate, or Dataverse.</p> </li> <li> <p>Select the specific resource that you want to monitor from the \\\"Resource\\\" dropdown list. For example, if you selected Power Apps as the resource type, you can select a specific app to monitor.</p> </li> <li> <p>Select the conditions that will trigger the alert. You can choose from a variety of conditions, such as when the resource reaches a certain threshold of usage, when a specific action is performed, or when an error occurs.</p> </li> <li> <p>Choose the action that will be taken when the alert is triggered. You can choose to receive an email notification, a text message, or a push notification to your mobile device.</p> </li> <li> <p>Click \\\"Save\\\" to save the alert rule. </p> </li> <li> <p>Once the alert rule is saved, you can view it in the \\\"Alert rules\\\" section of the environment\\'s settings.</p> </li> <li> <p>You can also edit or delete existing alert rules by selecting them from the \\\"Alert rules\\\" section and clicking on the appropriate button.</p> </li> </ol>"},{"location":"mon/#how-to-integrate-alerts-for-azure-devops","title":"How to Integrate alerts for Azure DevOps","text":"<ol> <li> <p>Log in to the Azure DevOps portal (https://dev.azure.com) with     your credentials.</p> </li> <li> <p>In the left-hand navigation pane, select the project for which you     want to configure alerts.</p> </li> <li> <p>Click on the \\\"Project settings\\\" gear icon in the bottom left     corner of the screen.</p> </li> <li> <p>Select \\\"Notifications\\\" under the \\\"General\\\" tab.</p> </li> <li> <p>Click on the \\\"New Subscription\\\" button to create a new alert     subscription.</p> </li> <li> <p>Choose the type of events that you want to receive alerts for. You     can select from a variety of events, such as when a work item is     created or updated, when a build completes, or when a pull request     is merged.</p> </li> <li> <p>Select the target for the alert. You can choose to send the alert to     a specific email address, to a group of email addresses, or to a     webhook URL.</p> </li> <li> <p>Configure the details of the alert subscription. Depending on the     type of event you selected, you may be asked to provide additional     information, such as the type of work item or build pipeline to     monitor.</p> </li> <li> <p>Click on the \\\"Create\\\" button to create the alert subscription.</p> </li> <li> <p>Once the alert subscription is created, you can view and manage it     under the \\\"Notifications\\\" tab.</p> </li> <li> <p>You can edit or delete existing alert subscriptions by selecting     them from the list and clicking on the appropriate button.</p> </li> </ol>"},{"location":"performance/","title":"Performance \u26a1","text":"<p>Git stands out with its performance advantages. Performance optimized operations are branching and merging, committing new changes, and the comparison of the past versions. One of the Git performance strengths is its advanced algorithms.</p> <p>Git focuses only on the file content while determining its storage and version history of the tree. The source code files are renamed, split, and rearranged regularly. The object format of Git repository files uses a mixture of delta encoding and compression. It stores directory contents and version metadata objects.</p>"},{"location":"profile/","title":"Profile","text":""},{"location":"profile/#profile-summary","title":"Profile Summary","text":"<ul> <li>Experience in IT area comprising the configuration management, Deploy, CI/CD pipeline, AWS, and DevOps methodologies.   </li> <li>Proven experience on creates Branching and Tagging concepts in Version Control tool like GIT.</li> <li>Proven experience on Build Tools like Maven, ANT. </li> <li>Experience on building and deploying Java web applications in Apache Tomcat. </li> <li>Good experience in automating build process using Jenkins tools. </li> <li>Experience in working with Amazon Web Services (AWS), Creating EC2 Instances and configuring all web Services like EC2, S3 bucket, ELB, IAM through AWS Console. </li> <li>Worked on Dockers Including Docker Installation, Creating Images and Containers. </li> <li>Expertise in creating DevOps strategy in a mix environment of Linux (RHEL, CENTOS,) servers along with Amazon Web Services. </li> <li>Analyzing application logs in order to determine the possible cause of issues and reporting errors directly to the Dev team. </li> <li>Proven experience on continuous Build and Deployments to multiple environments like Dev, QA, Performance and UAT.</li> <li>Managed daily builds and releases to QA. Debugged build failures and worked with developers and QA people to resolve related issues. </li> <li>Experience working on several Docker components like Docker Engine, Hub, Machine, Compose and Docker Registry. Implemented docker in Development and Testing environment using docker-compose and well versed in creating customized docker images using docker file. </li> <li>Worked on Container Tool Docker and Container orchestration on Kubernetes. </li> </ul>"},{"location":"profile/#technical-skills","title":"Technical Skills","text":"Category Skills Operating Systems Linux, Windows Cloud Platforms AWS, AZURE, GCP Basics Containerization Tools Docker, Kubernetes Automation Shell Scripting, Ansible, PowerShell Infrastructure Provisioning Cloud Formation, Terraform, Bicep Version Control Tool GIT, Azure Repo Build Software Maven CICD Jenkins, Azure DevOps Web/App Server Tomcat Static Web Development MkDocs Monitoring CloudWatch, Prometheus, Grafana"},{"location":"profile/#education","title":"Education","text":"Degree Field Year M.Tech Electronics and Communication Engineering 2019 B.Tech Electronics and Communication Engineering 2017 Diploma (Polytechnic) Electronics and Communication Engineering (ECE) 2014 10th Class Secondary School Certificate (SSC) 2011"},{"location":"security/","title":"Security \ud83d\udd12","text":"<p>The main priority of Git is the integrity of managed source code. In Git repository, versions, directories, the content of the file, tags, and commits are secure because a cryptographically secure SHA1 hashing algorithm is used, which ensures secure code history. Git provides an authentic content history of the source code.</p>"},{"location":"AWS/Create%20EC2%20instance/","title":"Here are the step-by-step instructions to create an Amazon Elastic Compute Cloud (EC2) instance in AWS:","text":"<p>Step 1: Sign in to the AWS Management Console.</p> <p>Step 2: Go to the EC2 service by searching for \"EC2\" in the search bar and selecting it from the results.</p> <p>Step 3: Click on the <code>\"Launch instance\"</code> button to start the EC2 instance creation process.</p> <p>Step 4: Choose an Amazon Machine Image (AMI) for your EC2 instance. This is the operating system and software stack that will be running on your instance.</p> <p>Step 5: Select an instance type that suits your needs in terms of CPU, memory, and storage capacity.</p> <p>Step 6: Configure the instance details, including the network settings, subnet, security group, and any additional settings required.</p> <p>Step 7: Add storage to your instance. You can specify the size and type of the root volume, and add any additional volumes if needed.</p> <p>Step 8: Configure any additional settings, such as user data, metadata, and tags for your instance.</p> <p>Step 9: Review your instance configuration and make any necessary changes.</p> <p>Step 10: Finally, click on the <code>\"Launch\"</code> button to create your EC2 instance.</p> <p>Step 11: You will be prompted to select or create a key pair. This key pair is used to securely access your instance via SSH.</p> <p>Step 12: Once the instance is launched, you can monitor its status in the EC2 dashboard. Once it is running, you can connect to it using SSH or other remote access methods.</p>"},{"location":"AWS/Create%20EC2%20instance/#create-an-ec2-instance-using-terraform-follow-these-step-by-step-instructions","title":"Create an EC2 instance using Terraform, follow these step-by-step instructions:","text":""},{"location":"AWS/Create%20EC2%20instance/#step-1-set-up-the-terraform-environment","title":"Step 1: Set up the Terraform environment.","text":"<p>Install Terraform on your local machine.</p> <p>Create a new directory for your Terraform project.</p>"},{"location":"AWS/Create%20EC2%20instance/#step-2-initialize-the-terraform-project","title":"Step 2: Initialize the Terraform project.","text":"<p>Open a terminal or command prompt and navigate to the project directory.</p> <p>Run the command: <code>terraform init</code></p> <p>This will initialize the project and download the necessary provider plugins.</p>"},{"location":"AWS/Create%20EC2%20instance/#step-3-create-a-terraform-configuration-file","title":"Step 3: Create a Terraform configuration file.","text":"<p>Create a new file with a .tf extension, such as <code>main.tf.</code></p> <p>Open the file in a text editor.</p>"},{"location":"AWS/Create%20EC2%20instance/#step-4-define-the-provider","title":"Step 4: Define the provider.","text":"<p>In the main.tf file, add the following code to specify the AWS provider:</p> <pre><code>provider \"aws\" {\n    region = \"us-west-2\"  # Replace with your desired region\n}\n</code></pre>"},{"location":"AWS/Create%20EC2%20instance/#step-5-define-the-ec2-instance-resource","title":"Step 5: Define the EC2 instance resource.","text":"<p>Below the provider block, add the following code to define the EC2 instance:</p> <pre><code>resource \"aws_instance\" \"example\" {\n  ami           = \"ami-xxxxxxxx\"  # Replace with your desired AMI ID\n  instance_type = \"t2.micro\"      # Replace with your desired instance type\n}\n</code></pre>"},{"location":"AWS/Create%20EC2%20instance/#step-6-save-the-configuration-file","title":"Step 6: Save the configuration file.","text":""},{"location":"AWS/Create%20EC2%20instance/#step-7-create-the-ec2-instance","title":"Step 7: Create the EC2 instance.","text":"<p>In the terminal, run the command: <code>terraform apply</code></p> <p>Terraform will display a plan of the changes it will make.</p> <p>Type yes to confirm and create the EC2 instance.</p> <p>Terraform will provision the resources and display the output.</p> <p>Step 8: Verify the EC2 instance in the AWS Management Console.</p> <p>Open the AWS Management Console and navigate to the EC2 service.</p> <p>Confirm that the newly created EC2 instance is listed.</p> <p>To manage and update your EC2 instance with Terraform, you can modify the configuration file (main.tf) and then re-run the terraform apply command.</p>"},{"location":"AWS/Create%20EC2%20instance/#note-before-running-terraform-commands-ensure-you-have-properly-configured-your-aws-credentials-using-the-aws-cli-or-environment-variables","title":"Note: Before running Terraform commands, ensure you have properly configured your AWS credentials using the AWS CLI or environment variables.","text":""},{"location":"AWS/Create%20RDS/","title":"Create RDS \ud83d\uddc3\ufe0f","text":"<p>Amazon Relational Database Service (RDS) is a managed database service provided by Amazon Web Services (AWS). It allows you to easily set up, operate, and scale a relational database in the cloud. RDS supports various database engines, including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle, and Microsoft SQL Server.</p>"},{"location":"AWS/Create%20RDS/#to-create-an-amazon-rds-instance-follow-these-steps","title":"To create an Amazon RDS instance, follow these steps:","text":"<ol> <li> <p>Sign in to the AWS Management Console: Go to the AWS Management Console 'Aws Console' and sign in using your AWS account credentials.</p> </li> <li> <p>Open the RDS service: Once you're logged in, open the AWS Management Console and search for \"RDS\" in the search bar. Click on the \"Amazon RDS\" result that appears.</p> </li> <li> <p>Choose a database engine: On the Amazon RDS dashboard, click on the \"Create database\" button.</p> </li> </ol> <p>4.Select the database engine: In the \"Create database\" wizard, choose the desired database engine you want to use for your RDS instance. You can select from options like Amazon Aurora, PostgreSQL, MySQL, etc. Click on the engine of your choice.</p> <ol> <li> <p>Specify the DB details: Fill in the required details such as DB instance identifier, username, and password. You can also choose the instance size, storage type, allocated storage, and other configuration options based on your requirements.</p> </li> <li> <p>Configure advanced settings: If you have specific requirements, you can configure advanced settings such as VPC, subnet group, database options, security groups, backups, and monitoring. Adjust these settings as needed.</p> </li> <li> <p>Set up the database: Configure additional settings like database name, port number, master username, and password. You can also enable options like automated backups, monitoring, and performance insights.</p> </li> <li> <p>Choose the storage: Select the storage type (e.g., General Purpose SSD, Provisioned IOPS, Magnetic) and specify the allocated storage size based on your needs.</p> </li> <li> <p>Configure the networking: Choose the appropriate virtual private cloud (VPC) and subnet group for your RDS instance. You can also specify the publicly accessible settings and configure network security using security groups.</p> </li> <li> <p>Review and create: Review all the configuration details you have provided in the previous steps. Double-check the settings to ensure they are correct. If everything looks good, click on the \"Create database\" button.</p> </li> <li> <p>Wait for the RDS instance creation: AWS will now create your RDS instance based on the specified configuration. This process may take a few minutes.</p> </li> <li> <p>Access and use the RDS instance: Once the RDS instance is created successfully, you can access it using the provided endpoint. Use the appropriate database client or tools to connect to your RDS instance and start using it.</p> </li> </ol>"},{"location":"AWS/Create%20RDS/#create-an-amazon-rds-instance-using-terraform","title":"create an Amazon RDS instance using Terraform.","text":"<p>To create an Amazon RDS instance using Terraform, you need to have Terraform installed and configured on your local machine. Follow these steps to create an RDS instance using Terraform:</p> <ol> <li> <p>Initialize a new Terraform project: Create a new directory for your Terraform project and navigate to it using the command line. Run the command terraform init to initialize the project and download the necessary provider plugins.</p> </li> <li> <p>Create a Terraform configuration file: Create a new file with a .tf extension (e.g., main.tf) and open it in a text editor. This file will contain the Terraform configuration for creating the RDS instance.</p> </li> <li> <p>Configure the AWS provider: In your main.tf file, add the following code to configure the AWS provider:</p> </li> </ol> <pre><code>provider \"aws\" {\n  region = \"your_region\"\n  access_key = \"your_access_key\"\n  secret_access_key = \"your_secret_access_key\"\n}\n</code></pre> <p>Replace your_region with the desired AWS region where you want to create the RDS instance. Replace your_access_key and your_secret_access_key with your own AWS access key and secret access key. Alternatively, you can set environment variables or use other authentication methods supported by Terraform.</p> <ol> <li>Define the RDS instance resource: Add the following code to define the RDS instance resource in your main.tf file:</li> </ol> <pre><code>resource \"aws_db_instance\" \"example\" {\n  identifier             = \"example-rds-instance\"\n  engine                 = \"mysql\"\n  engine_version         = \"8.0\"\n  instance_class         = \"db.t3.micro\"\n  allocated_storage      = 20\n  storage_type           = \"gp2\"\n  username               = \"db_user\"\n  password               = \"db_password\"\n  name                   = \"example_database\"\n  parameter_group_name   = \"default.mysql8.0\"\n  publicly_accessible    = false\n\n  vpc_security_group_ids = [\n    \"sg-12345678\",\n    \"sg-87654321\"\n  ]\n\n  tags = {\n    Name = \"Example RDS Instance\"\n  }\n}\n</code></pre> <p>Terraform will show you a preview of the resources it will create. Review the plan, and if everything looks good, type \"yes\" when prompted to confirm and create the RDS instance.</p> <ol> <li>Wait for the RDS instance creation: Terraform will create the RDS instance according to the specified configuration. This process may take a few minutes. You can monitor the progress in the command line. Once the RDS instance creation is complete, you will see the output in the command line. You can now use the RDS instance for your applications by connecting to it using the provided endpoint.</li> </ol> <p>Remember to manage your Terraform state files properly and use best practices for versioning and infrastructure-as-code workflows with Terraform.</p>"},{"location":"AWS/Create%20S3%20Bucket/","title":"Create S3 Bucket \ud83d\udcc2","text":"<p>Amazon Simple Storage Service (S3) is a scalable and highly durable cloud storage service provided by Amazon Web Services (AWS). It is designed to store and retrieve any amount of data from anywhere on the web. S3 offers a simple interface to manage and access your data, making it suitable for a wide range of use cases such as data backup, static website hosting, content distribution, and data archiving.</p>"},{"location":"AWS/Create%20S3%20Bucket/#here-are-the-step-by-step-instructions-to-create-an-s3-bucket-in-aws","title":"Here are the step-by-step instructions to create an S3 bucket in AWS:","text":"<p>Step 1: Sign in to the AWS Management Console.</p> <p>Step 2: Search for \"S3\" in the AWS service search bar and select \"S3\" from the results.</p> <p>Step 3: Click on the \"Create bucket\" button to initiate the bucket creation process.</p> <p>Step 4: Provide a unique and meaningful name for your bucket. The bucket name must be globally unique across all existing S3 bucket names.</p> <p>Step 5: Select the region in which you want to create the bucket. Consider choosing a region that is closest to your anticipated users or resources for better performance.</p> <p>Step 6: Configure the bucket properties:</p> <p>Enable or disable versioning: Versioning allows you to preserve, retrieve, and restore every version of every object in your bucket.</p> <p>Configure server access logging: You can enable logging to record detailed access logs for your S3 bucket.</p> <p>Configure default encryption: You can choose to enable default encryption for objects stored in the bucket.</p> <p>Step 7: Set up bucket permissions:</p> <p>Configure bucket access control: You can define who can access your bucket and its contents by managing bucket policies, access control lists (ACLs), or AWS Identity and Access Management (IAM) policies.</p> <p>Block public access settings: You can choose to block public access to your bucket if it contains sensitive data.</p> <p>Step 8: Review your bucket configuration and click on the \"Create bucket\" button to create the S3 bucket.</p> <p>Step 9: Once the bucket is created, you can start using it to store and retrieve data. You can upload files, create folders (called \"directories\" in S3), and manage the bucket's settings as needed.</p> <p>It is important to understand and configure the appropriate access permissions and security measures for your S3 bucket to ensure the confidentiality, integrity, and availability of your data.</p> <p>Please note that the above steps provide a general outline for creating an S3 bucket. The AWS Management Console may undergo updates or changes, so it's always recommended to refer to the AWS documentation or consult an AWS expert for the most up-to-date and detailed guidance on creating an S3 bucket in your AWS account.</p>"},{"location":"AWS/Create%20S3%20Bucket/#heres-a-simple-example-of-terraform-code-to-create-an-s3-bucket","title":"Here's a simple example of Terraform code to create an S3 bucket:","text":"<p>Step 1: Start by opening a Terraform configuration file (with a .tf extension) in a text editor.</p> <p>Step 2: Define the AWS provider in the configuration file by adding the following code:</p> <pre><code>provider \"aws\" {\n  region = \"us-west-2\"  # Replace with your desired region\n}\n</code></pre> <p>Make sure to replace \"us-west-2\" with the desired AWS region.</p> <p>Step 3: Create an S3 bucket resource by adding the following code:</p> <pre><code>resource \"aws_s3_bucket\" \"example_bucket\" {\n  bucket = \"my-example-bucket\"  # Replace with your desired bucket name\n}\n</code></pre> <p>Replace \"my-example-bucket\" with your desired bucket name.</p> <p>Step 4: Customize the configuration by adding additional properties or parameters to the aws_s3_bucket resource block. </p> <p>For example, you can enable versioning, configure access control, define lifecycle rules, and more. Modify the code as needed.</p> <p>Step 5: Save the configuration file.</p> <p>Step 6: Open a terminal or command prompt and navigate to the directory where the configuration file is saved.</p> <p>Step 7: Initialize the Terraform project by running the command:</p> <pre><code>terraform init\n</code></pre> <p>This command initializes the project and downloads the necessary provider plugins.</p> <p>Step 8: Apply the Terraform configuration to create the S3 bucket by running the command:</p> <pre><code>terraform apply\n</code></pre> <p>Terraform will display a plan of the changes it will make. Type <code>yes</code> and press Enter to confirm and create the S3 bucket.</p> <p>Step 9: Wait for Terraform to provision the resources. Once completed, you will see the output in the terminal.</p> <p>Note: Ensure that you have properly configured your AWS credentials before running Terraform commands, either through the AWS CLI or environment variables.</p> <p>By following these steps, you can create an S3 bucket using Terraform with the provided code.</p>"},{"location":"AWS/EBS/","title":"Amazon Elastic Block Store (EBS) \ud83d\ude80","text":"<p>Amazon Elastic Block Store (EBS) is a block-level storage service provided by Amazon Web Services (AWS) that offers persistent storage volumes for EC2 instances. EBS volumes are highly available and reliable, allowing you to store data for applications and databases running on EC2 instances.</p>"},{"location":"AWS/EBS/#to-create-an-amazon-ebs-volume-and-attach-it-to-an-ec2-instance-follow-these-step-by-step-instructions","title":"To create an Amazon EBS volume and attach it to an EC2 instance, follow these step-by-step instructions:","text":"<p>Step 1: Sign in to the AWS Management Console.</p> <p>Step 2: Open the Amazon EC2 console at AWS Console</p> <p>Step 3: In the navigation pane, click on \"Volumes.\"</p> <p>Step 4: Click on the \"Create Volume\" button.</p> <p>Step 5: Configure the following settings:</p> <pre><code>Volume Type: Select the appropriate volume type based on your requirements (e.g., General Purpose SSD, Provisioned IOPS SSD, Throughput Optimized HDD, Cold HDD).\n\nSize: Specify the size of the volume in GiB.\n\nAvailability Zone: Choose the same availability zone as your EC2 instance.\n\nEncryption: Optionally, select the encryption option if you want to encrypt the volume.\n\nTags: Add any tags that you want to associate with the volume (optional).\n</code></pre> <p>tep 6: Click on the \"Create Volume\" button to create the EBS volume.</p> <p>Step 7: Once the volume is created, go back to the \"Volumes\" page and select the newly created volume.</p> <p>Step 8: Click on the \"Actions\" button and choose \"Attach Volume.\"</p> <p>Step 9: In the \"Attach Volume\" dialog box, select the EC2 instance to which you want to attach the volume.</p> <p>Step 10: Specify the device name (e.g., /dev/xvdf) to which the volume will be attached.</p> <p>Step 11: Click on the \"Attach\" button to attach the EBS volume to the EC2 instance.</p> <p>Once the volume is attached to the EC2 instance, you can access it like any other block storage device within the operating system of the instance. You may need to format the volume and mount it to use it for your applications or databases.</p> <p>Note: Make sure that the EC2 instance and the EBS volume are in the same availability zone for successful attachment.</p>"},{"location":"AWS/EBS/#create-an-amazon-rds-relational-database-service-instance-using-terraform-you-need-to-follow-these-steps","title":"Create an Amazon RDS (Relational Database Service) instance using Terraform, you need to follow these steps:","text":"<p>Step 1: Install Terraform: Download and install Terraform from the official website (https://www.terraform.io/downloads.html) and set it up on your local machine.</p> <p>Step 2: Initialize a Terraform project: Create a new directory for your Terraform project and navigate to it in your terminal. Initialize the directory as a Terraform project by running the following command:</p> <pre><code>terraform init\n</code></pre> <p>Step 3: Configure AWS Provider: Create a file named main.tf in your project directory and add the following code to configure the AWS provider. Replace  and  with your AWS credentials. <pre><code>provider \"aws\" {\n  access_key = \"&lt;AWS_ACCESS_KEY&gt;\"\n  secret_access_key = \"&lt;AWS_SECRET_ACCESS_KEY&gt;\"\n  region = \"us-east-1\"   # Replace with your desired region\n}\n</code></pre> <p>Step 4: Define RDS instance configuration: Create a new file named rds.tf and add the following code to define the configuration for your RDS instance. Customize the values based on your requirements.</p> <pre><code>resource \"aws_db_instance\" \"example\" {\n  identifier            = \"my-rds-instance\"\n  engine                = \"mysql\"  # Replace with your desired database engine\n  instance_class        = \"db.t2.micro\"\n  allocated_storage     = 20\n  storage_type          = \"gp2\"\n  username              = \"admin\"  # Replace with your desired username\n  password              = \"password\"  # Replace with your desired password\n  db_subnet_group_name  = \"my-db-subnet-group\"\n  vpc_security_group_ids = [\"sg-12345678\"]  # Replace with your desired security group(s)\n\n  # Additional optional configuration\n  multi_az              = false\n  publicly_accessible  = false\n  backup_retention_period = 7\n}\n\n</code></pre> <p>Step 5: Initialize and apply the Terraform configuration: Run the following command in your project directory to initialize and apply the Terraform configuration, which will create the RDS instance:</p> <pre><code>terraform init\n\nterraform apply\n\n</code></pre> <p>Review the planned changes, and if they look correct, type \"yes\" to proceed with the creation of the RDS instance.</p> <p>Terraform will then provision the RDS instance according to the specified configuration. Once the process is complete, it will display the details of the created RDS instance.</p> <p>Please note that this is a basic example, and you may need to modify the configuration based on your specific requirements, such as specifying database parameters, subnet groups, and security groups.</p> <p>Remember to manage your AWS credentials securely and follow best practices for storing sensitive information.</p>"},{"location":"AWS/List%20of%20Aws%20Services/","title":"List of Aws Services \ud83d\udce6","text":""},{"location":"AWS/List%20of%20Aws%20Services/#list-of-aws-services","title":"List of AWS Services","text":"S.No. Service Name Usage 1 Amazon Elastic Compute Cloud (EC2) Provides resizable compute capacity for running virtual servers. 2 Amazon Simple Storage Service (S3) Object storage service for storing and retrieving data, files, and websites. 3 Amazon Relational Database Service (RDS) Managed relational database service for MySQL, PostgreSQL, SQL Server, and more. 4 Amazon Elastic Block Store (EBS) Block storage volumes for use with EC2 instances to store data. 5 Amazon Virtual Private Cloud (VPC) Isolates and secures your network in the cloud, providing private IP addresses. 6 Amazon CloudFront Content delivery network (CDN) for securely delivering data, videos, and applications. 7 AWS Lambda Runs code in response to events and automatically manages the computing resources. 8 Amazon Simple Queue Service (SQS) Managed message queuing service for decoupling the components of cloud applications. 9 Amazon Simple Notification Service (SNS) Pub/sub messaging service for sending messages to a distributed set of recipients. 10 Amazon Simple Email Service (SES) Sending and receiving email using a scalable and cost-effective cloud service. 11 Amazon Elastic Load Balancer (ELB) Automatically distributes incoming application traffic across multiple targets. 12 Amazon CloudWatch Monitoring and observability service for cloud resources and applications. 13 Amazon CloudFormation Infrastructure as code service to create and provision AWS infrastructure resources. 14 Amazon Simple Workflow Service (SWF) Workflow service for building applications with human tasks and asynchronous steps. 15 Amazon Elastic MapReduce (EMR) Big data platform for processing vast amounts of data using popular frameworks. 16 AWS Identity and Access Management (IAM) Securely control access to AWS services and resources for your users and applications. 17 Amazon Route 53 Scalable domain name system (DNS) web service for routing traffic to web applications. 18 AWS Direct Connect Establish a dedicated network connection from your on-premises data center to AWS. 19 Amazon Elastic Container Service (ECS) Orchestrates and manages Docker containers for deploying applications. 20 AWS Elastic Beanstalk Platform as a Service (PaaS) for deploying and managing applications in various languages. 21 AWS CloudTrail Records AWS API calls for your account and delivers log files for security and compliance. 22 Amazon SimpleDB A non-relational database for storage and querying structured data. 23 Amazon DynamoDB Managed NoSQL database service for applications requiring seamless scaling and high performance. 24 Amazon Aurora Relational database service that combines the performance and availability of high-end commercial databases with the simplicity and cost-effectiveness of open-source databases. 25 Amazon Redshift Fully managed data warehouse service for running complex queries on large datasets. 26 AWS Elastic Transcoder Media transcoding in the cloud for converting media files between different formats. 27 Amazon Kinesis Collect and process real-time data streams such as video, audio, application logs, etc. 28 Amazon Glacier Low-cost cloud storage service for data archiving and long-term backup. 29 AWS Key Management Service (KMS) Managed encryption service for creating and controlling access to encryption keys. 30 AWS Glue ETL (Extract, Transform, Load) service for preparing and loading data to data stores. 31 Amazon CloudSearch Managed search service for integrating fast and scalable search capabilities into applications. 32 Amazon SimpleDB A non-relational database for storage and querying structured data. 33 AWS Batch Fully managed batch processing at any scale for applications that require batch computing. 34 Amazon Elastic File System (EFS) Scalable file storage service for use with EC2 instances for applications and workloads. 35 Amazon WorkSpaces Desktop as a Service (DaaS) solution for secure and scalable remote desktops. 36 AWS CodeCommit Fully managed source control service to host secure and scalable Git repositories."},{"location":"AWS/aws/","title":"AWS","text":""},{"location":"AWS/aws/#here-are-the-steps-to-create-an-aws","title":"Here are the steps to create an AWS :","text":"<ol> <li>Visit the AWS website: AWS Website 'Aws portal Link'</li> <li>Click on the \"Create an AWS Account\" button.</li> <li>Fill in your email address and create a password for your AWS account.</li> <li>Provide your contact information, including your name and phone number.</li> <li>Enter your company or personal information, such as your company name or your full name if you're signing up as an individual.</li> <li>Provide your payment information. AWS requires a valid credit card to create an account, although some services offer a free tier.</li> <li>Read and accept the AWS Customer Agreement.</li> <li>Choose a support plan. AWS offers different levels of support, including a free plan with basic support and paid plans with more advanced support options.</li> <li>Complete the identity verification process. This may involve receiving a phone call or entering a verification code sent to your email or phone number.</li> <li>Set up your billing preferences, including your billing address and whether you want to receive invoices via email or through the AWS Management Console.</li> <li>Review your account details and confirm your account creation.</li> <li>You will receive a confirmation email from AWS with further instructions.</li> <li>Follow the instructions in the email to activate your AWS account.</li> </ol> <p>Congratulations! You have successfully created an AWS account. You can now log in to the AWS Management Console and start using AWS services and resources.</p>"},{"location":"GitHub/Advantages/","title":"Advantages","text":""},{"location":"GitHub/Advantages/#advanatges-of-github","title":"Advanatges of GitHub","text":"<ol> <li> <p>Version Control: GitHub is built on top of Git, a powerful distributed version control system. It allows developers to track changes, collaborate on code, and easily revert to previous versions if issues arise.</p> </li> <li> <p>Collaboration: Multiple developers can work on the same project simultaneously, making it easy to collaborate on coding projects. GitHub provides features like pull requests, code reviews, and issue tracking to facilitate collaboration.</p> </li> <li> <p>Centralized Repository: GitHub provides a central location to host and manage code repositories, making it easy for teams to access and work on projects from anywhere in the world.</p> </li> <li> <p>Community and Open Source: GitHub is a hub for open source projects. It facilitates community contributions, allowing developers from around the world to collaborate on and contribute to open source software.</p> </li> <li> <p>Issue Tracking: GitHub includes a robust issue tracking system that helps teams manage tasks, bugs, and feature requests. Issues can be assigned, labeled, and prioritized, making it easier to manage and address them.</p> </li> <li> <p>Code Review: Pull requests in GitHub allow developers to review code changes before they are merged into the main codebase. This helps maintain code quality and ensures that changes are thoroughly reviewed.</p> </li> <li> <p>Automation: GitHub Actions allows for the automation of various tasks, including code testing, building, and deployment. This automation can save time and reduce manual errors.</p> </li> <li> <p>Continuous Integration and Continuous Deployment (CI/CD): GitHub seamlessly integrates with various CI/CD tools and services, making it easier to set up automated testing and deployment pipelines.</p> </li> <li> <p>Security: GitHub offers security features like vulnerability scanning, dependency analysis, and code scanning to help identify and address security issues in codebases.</p> </li> <li> <p>Documentation: GitHub provides a platform for hosting project documentation, wikis, and README files. Clear and well-maintained documentation is essential for onboarding new contributors and users.</p> </li> <li> <p>Community and Learning: GitHub has a vast and active community of developers and users. It's a great place to learn, share knowledge, and discover new projects and technologies.</p> </li> <li> <p>Integrations: GitHub supports numerous integrations with other development tools, such as IDEs, project management tools, and notification services, enhancing the development workflow.</p> </li> <li> <p>Data Insights: GitHub offers insights into codebase activity, contributions, and usage statistics, helping project maintainers and administrators make informed decisions.</p> </li> <li> <p>Customization: GitHub repositories can be customized with various settings, such as branch protection rules, webhooks, and access control, to meet specific project requirements.</p> </li> <li> <p>Scalability: GitHub can accommodate projects of all sizes, from small personal repositories to large enterprise-scale codebases.</p> </li> <li> <p>Git LFS: GitHub provides support for Git Large File Storage (LFS), allowing teams to manage large binary files efficiently.</p> </li> <li> <p>Reliability and Uptime: GitHub is known for its high availability and uptime, ensuring that your code and data are accessible when you need them.</p> </li> <li> <p>Education and Learning Resources: GitHub provides educational resources, including GitHub Learning Lab and GitHub Classroom, to help students and educators learn and teach software development effectively.</p> </li> </ol>"}]}